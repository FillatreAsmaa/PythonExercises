{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is based on Python 3.5.\n",
    "\n",
    "I propose two code versions: 1) without chunck (the whole file is processed in a single step) and 2) with chunks (when the file is processed in multiple steps). The results are obviously identical.\n",
    "\n",
    "To accelerate the performance, I used an uncompressed data file but, if necessary, the \"pd.read_csv\" function can be applied to compressed files by adding the option \"compression='bz2'\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines the common parameters of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd # import the library pandas\n",
    "import numpy as np # import the library numpy to use \"linspace\"\n",
    "filenameBooking=\"bookings.csv\" # name of the bookings file\n",
    "usedColumns = ['arr_port','pax'] # columns used to process the file\n",
    "intChunksize = 10000 # size of the chunk (when using chunks)\n",
    "topNumber=10 # number of tops I retrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell computes the top10 by processing the file in one single step (without chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " arr_port    pax\n",
      " LHR       88809\n",
      " MCO       70930\n",
      " LAX       70530\n",
      " LAS       69630\n",
      " JFK       66270\n",
      " CDG       64490\n",
      " BKK       59460\n",
      " MIA       58150\n",
      " SFO       58000\n",
      " DXB       55590\n"
     ]
    }
   ],
   "source": [
    "# Version without chunk\n",
    "# read the CSV file, keeping only columns 'arr_port' and'pax'\n",
    "df = pd.read_csv(filenameBooking,sep='^', usecols=usedColumns) \n",
    "# The next command works as follow:\n",
    "# 1)The grouby operator groups the dataframe rows by arrival airport, then I sum the pax (including negatives values)\n",
    "# 2) the function \"reset_index\" transforms the hierarchical index levels (created with the groupby) into columns, \n",
    "# so I obtain a dataframe\n",
    "# 3) The column \"pax\" is sorted on descending order and I keep the first topNumber rows\n",
    "# Comment: If a value is missing within the file,the read_csv function replaces it automatically by a nan, \n",
    "# and the sum ignores the nan's.\n",
    "dfTop=df['pax'].groupby(df['arr_port']).sum().reset_index().sort_values(by='pax', ascending=False)[:topNumber]\n",
    "print(dfTop.to_string(index=False)) # print the top10 dataframe (just for verification, no \"pretty\" print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell computes the top10 by processing the file by using chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Version with chunks\n",
    "df = pd.read_csv(filenameBooking,sep='^', usecols=usedColumns,chunksize=intChunksize) \n",
    "dfConcatenated = pd.DataFrame(columns=usedColumns) # initialization: empty dataframe\n",
    "\n",
    "for chunk in df: # loop over the chunks\n",
    "    # partial dataframe \"dfChunk\" for each chunk\n",
    "    dfChunk=chunk.groupby(chunk['arr_port']).sum().reset_index() \n",
    "    # concatenating the partial dataframes ignore overlapping indexes, due to option \"ignore_index=True\"\n",
    "    dfConcatenated = pd.concat([dfConcatenated, dfChunk], ignore_index=True) # I concatenate recursively all the partial dataframes \n",
    "\n",
    "# Compute the top10 from the concatenated dataframe \"dfConcatenated\"    \n",
    "dfTopChunk=dfConcatenated['pax'].groupby(dfConcatenated['arr_port']).sum().reset_index().sort_values(\n",
    "    by='pax', ascending=False)[:topNumber]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next cell, I change the organization of dfTopChunk to print a \"pretty\" dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rank   Airport  Number of bookings\n",
      "    1  LHR                    88809\n",
      "    2  MCO                    70930\n",
      "    3  LAX                    70530\n",
      "    4  LAS                    69630\n",
      "    5  JFK                    66270\n",
      "    6  CDG                    64490\n",
      "    7  BKK                    59460\n",
      "    8  MIA                    58150\n",
      "    9  SFO                    58000\n",
      "   10  DXB                    55590\n"
     ]
    }
   ],
   "source": [
    "dfTopChunk['Rank']=np.linspace(1,topNumber,topNumber)\n",
    "dfTopChunk = dfTopChunk.reindex(columns=['Rank','arr_port','pax'])\n",
    "dfTopChunkPrinted=dfTopChunk.rename(columns={'arr_port': 'Airport','pax': 'Number of bookings'})\n",
    "print(dfTopChunkPrinted.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
