{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "This code is based on Python 3.5.\n",
    "\n",
    "I read files with chunks because the process is ressource demanding, especially the joint operation.\n",
    "\n",
    "A special attention is devoted to data format (for airport origin, airport destination and date) because a bad data format yields mismatch problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# common parameters of the code\n",
    "import pandas as pd \n",
    "\n",
    "# important filenames\n",
    "strSearchesFilename='searches.csv' \n",
    "strBookingsFilename='bookings.csv' \n",
    "\n",
    "# To obtain a reasonable computation time, the chunk size should be large \n",
    "intChunksize=10000000 \n",
    "\n",
    "# Columns for joining the bookings and the searches\n",
    "# It is assumed that the data in searches.csv should match with the date in bookings\n",
    "listColumnsSearchesInner=['Origin', 'Destination', 'Date']\n",
    "listColumnsBookingInner=['dep_port', 'arr_port','cre_date           ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines two functions to format correctly the important columns reading from the csv files.\n",
    "The problem of format causes mismatch inconsistencies when associating bookings and searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the \"strip\" function removes the whitespace to avoid mismatch problem when joining the data\n",
    "# The text format of 'dep_port' and 'arr_port' are not identical to 'Origin' and 'Destination'\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text\n",
    "    \n",
    "# I read the file and declare NaT the dates uncorrectly formatted\n",
    "# The correct format is '%Y-%m-%d'\n",
    "parse = lambda x: pd.to_datetime(x, format='%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read the file and declare NaT the dates uncorrectly formatted.\n",
    "\n",
    "The correct format is '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve the columns of \"searches.csv\"  (0 line is read)\n",
    "dfSearchCol = pd.read_csv(strSearchesFilename,sep='^',nrows=0)\n",
    "listColumnsSearches=list(dfSearchCol.columns.values)  \n",
    "listAllColumns=listColumnsSearches+listColumnsBookingInner\n",
    "\n",
    "del dfSearchCol  # delete the dataframe to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell works as follows:\n",
    "\n",
    "1- I read the searches file\n",
    "\n",
    "2- I read the bookings file\n",
    "\n",
    "3- I use an inner joint to match the searches with the bookings (keeping only the relevant columns)\n",
    "\n",
    "4- I accumulate the records w.r.t. the bookings chunks.\n",
    "\n",
    "5- The output file is writing in CSV format iteratively chunk after chunck. I delete temporary dataframes to save memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read searches.csv, all the columns of interests\n",
    "# All the formating operations are made during the reading step in order to minimize the computational effort\n",
    "dfSearch = pd.read_csv(strSearchesFilename,sep='^', \n",
    "                       usecols=listColumnsSearches,\n",
    "                       parse_dates=[listColumnsSearchesInner[2]],date_parser=parse,\n",
    "                       converters = {listColumnsSearchesInner[0] : strip,\n",
    "                                     listColumnsSearchesInner[1] : strip},\n",
    "                       dtype={listColumnsSearches[40]:'object',\n",
    "                              listColumnsSearches[41]:'object',\n",
    "                              listColumnsSearches[42]:'object',\n",
    "                              listColumnsSearches[44]:'object'},\n",
    "                       chunksize=intChunksize)\n",
    "# Loop over the searches with chunks\n",
    "for chunkS in dfSearch:\n",
    "    dfConcatenated = pd.DataFrame(columns=listAllColumns) # initialization: empty dataframe whose columns correspond\n",
    "                                                       # to the columns of the final output file\n",
    "    # read bookings.csv, only the column of interests given in bookingColumns and chunk per chunk \n",
    "    # in order to retrieve a corresponding record within chunkS\n",
    "    # All the formating operations are made during the reading step in order to minimize the computational effort\n",
    "    dfBook = pd.read_csv(strBookingsFilename,sep='^', \n",
    "                         usecols=listColumnsBookingInner,\n",
    "                         parse_dates=[listColumnsBookingInner[2]],date_parser=parse,\n",
    "                         converters = {listColumnsBookingInner[0] : strip, # remove whitespaces in the columns\n",
    "                                       listColumnsBookingInner[1] : strip},\n",
    "                         chunksize=intChunksize) # read the CSV file, keeping only columns in bookingColumns\n",
    " \n",
    "    # Loop over the dataframe dfBook for the bookings\n",
    "    for chunkB in dfBook:\n",
    "        # The inner joint keeps only the common records\n",
    "        dfMergeSB = pd.merge(chunkS, chunkB, \n",
    "                             left_on=listColumnsSearchesInner, \n",
    "                             right_on=listColumnsBookingInner, \n",
    "                             how='inner')       \n",
    "        dfConcatenated=pd.concat([dfConcatenated, dfMergeSB]) # I append the new relevant records to the previous one\n",
    "        \n",
    "    del dfConcatenated        # delete a dataframe to save memory    \n",
    "    del dfMergeSB             # delete a dataframe to save memory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
