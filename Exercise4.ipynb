{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "This code is based on Python 3.5.\n",
    "\n",
    "I read files with chunks because the process is ressource demanding, especially the join operations. I use a PC with Windows 10 and 32 GB RAM, so the proposed chuck size is rather large.\n",
    "\n",
    "A special attention is devoted to data format (for airport origin, airport destination and date) because a bad data format yields mismatch problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Common parameters of the code\n",
    "import pandas as pd \n",
    "\n",
    "# Important filenames\n",
    "strSearchesFilename='searches.csv' \n",
    "strBookingsFilename='bookings.csv' \n",
    "strNewSearchesFilename='searcheswithbookings.csv' # output file\n",
    "\n",
    "# To obtain a reasonable computation time, the chunk size should be large \n",
    "intChunksize=10000000 \n",
    "\n",
    "# Columns for joining the bookings and the searches\n",
    "# It is assumed that the data in searches.csv should match with the date in bookings\n",
    "listColumnsSearchesInner=['Origin', 'Destination', 'Date']\n",
    "listColumnsBookingInner=['dep_port', 'arr_port','cre_date           ']\n",
    "listColBookingName='Booking' # new column in the searches file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines two functions to format correctly the important columns reading from the csv files.\n",
    "The problem of format causes mismatch inconsistencies when associating bookings and searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the \"strip\" function removes the whitespace to avoid mismatch problem when joining the data\n",
    "# The text format of 'dep_port' and 'arr_port' are not identical to 'Origin' and 'Destination'\n",
    "def strip(text):\n",
    "    try:\n",
    "        return text.strip()\n",
    "    except AttributeError:\n",
    "        return text\n",
    "    \n",
    "# I read the file and declare NaT the dates uncorrectly formatted\n",
    "# The correct format is '%Y-%m-%d'\n",
    "parse = lambda x: pd.to_datetime(x, format='%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read the file and declare NaT the dates uncorrectly formatted.\n",
    "\n",
    "The correct format is '%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# retrieve the columns of \"searches.csv\"  (0 line is read)\n",
    "dfSearchCol = pd.read_csv(strSearchesFilename,sep='^',nrows=0)\n",
    "listColumnsSearches=list(dfSearchCol.columns.values)  \n",
    "listAllColumns=listColumnsSearches+listColumnsBookingInner\n",
    "\n",
    "dfSearchCol[listColBookingName]=0 # Add the new column 'booking'\n",
    "usedColumns=listColumnsSearches+listColumnsBookingInner\n",
    "# Create an empty CSV file only with the column names\n",
    "dfSearchCol.to_csv(strNewSearchesFilename,sep='^',mode='w',index=False,header=True)  \n",
    "\n",
    "del dfSearchCol  # delete the dataframe to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell works as follows:\n",
    "\n",
    "1- I read the searches file\n",
    "\n",
    "2- I read the bookings file\n",
    "\n",
    "3- I use an inner joint to match the searches with the bookings (keeping only the relevant columns airport origin, airport destination and date)\n",
    "\n",
    "4- I accumulate the records w.r.t. the bookings chunks.\n",
    "\n",
    "5- I drop useless columns after the accumulation and the duplicated records.\n",
    "\n",
    "6- Finally, I create a new column called 'Booking' which contains 1 in case of booking matching, and 0 otherwise. The output file is generated with a left outer joint between the searches and the inner jointed bookings.\n",
    "\n",
    "7- The output file is writing in CSV format iteratively chunk after chunck. I delete temporary dataframes to save memory.\n",
    "\n",
    "The output file is written in CSV format iteratively chunk after chunck. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read searches.csv, all the columns of interests\n",
    "# All the formating operations are made during the reading step in order to minimize the computational effort\n",
    "# I precise the dtype of certain columns to avoid some warning: some columns are not type consistent \n",
    "# For example, a column can contain both a string and an integer.\n",
    "dfSearch = pd.read_csv(strSearchesFilename,sep='^', \n",
    "                       usecols=listColumnsSearches,\n",
    "                       parse_dates=[listColumnsSearchesInner[2]],date_parser=parse,\n",
    "                       converters = {listColumnsSearchesInner[0] : strip,\n",
    "                                     listColumnsSearchesInner[1] : strip},\n",
    "                       dtype={listColumnsSearches[40]:'object',\n",
    "                              listColumnsSearches[41]:'object',\n",
    "                              listColumnsSearches[42]:'object',\n",
    "                              listColumnsSearches[44]:'object'},\n",
    "                       chunksize=intChunksize)\n",
    "# Loop over the searches with chunks\n",
    "for chunkS in dfSearch:\n",
    "    dfConcatenated = pd.DataFrame(columns=listAllColumns) # initialization: empty dataframe whose columns correspond\n",
    "                                                       # to the columns of the final output file\n",
    "    # read bookings.csv, only the column of interests given in listColumnsBookingInner and chunk per chunk \n",
    "    # in order to retrieve a corresponding record within chunkS\n",
    "    # All the formating operations are made during the reading step in order to minimize the computational effort\n",
    "    dfBook = pd.read_csv(strBookingsFilename,sep='^', \n",
    "                         usecols=listColumnsBookingInner,\n",
    "                         parse_dates=[listColumnsBookingInner[2]],date_parser=parse,\n",
    "                         converters = {listColumnsBookingInner[0] : strip, # remove whitespaces in the columns\n",
    "                                       listColumnsBookingInner[1] : strip},\n",
    "                         chunksize=intChunksize) # read the CSV file, keeping only columns in listColumnsBookingInner\n",
    " \n",
    "    # Loop over the dataframe dfBook for the bookings\n",
    "    for chunkB in dfBook:\n",
    "        # The inner joint keeps only the common records\n",
    "        dfMergeSB = pd.merge(chunkS, chunkB, \n",
    "                             left_on=listColumnsSearchesInner, \n",
    "                             right_on=listColumnsBookingInner, \n",
    "                             how='inner')       \n",
    "        dfConcatenated=pd.concat([dfConcatenated, dfMergeSB]) # I append the new relevant records to the previous ones\n",
    "      \n",
    "    # I process below the dataframe dfConcatenated\n",
    "    # After reading all the dfBook, I drop the possible duplicates (w.r.t. colBook) inside the global dafa frame     \n",
    "    dfConcatenated.drop(listColumnsBookingInner, axis=1,inplace=True)\n",
    "    #dfConcatenated contains the rows from chunkS which are associated to at least one booking    \n",
    "    dfConcatenated=dfConcatenated.drop_duplicates().reset_index(drop=True)  # remove the possible duplicates of a row\n",
    "    dfConcatenated[listColBookingName]=1 # create a column of 1 with the name defined in listColBookingName\n",
    "    # If dfConcatenated is empty, the new column 'booking' will contain NaN values after the following merge\n",
    "    dfMergeSContatenated = pd.merge(chunkS, dfConcatenated, \n",
    "                                    left_on=listColumnsSearches, \n",
    "                                    right_on=listColumnsSearches, \n",
    "                                    how='left')     \n",
    "    # Transform NaN into 0 and 1 into 1    \n",
    "    dfMergeSContatenated[listColBookingName]=-(pd.isnull(dfMergeSContatenated[listColBookingName]).astype(int)-1)\n",
    "    # Append the resulting data frame to the file named in strNewSearchesFilename\n",
    "    dfMergeSContatenated.to_csv(strNewSearchesFilename,sep='^',mode='a',index=False,header=False)\n",
    "    \n",
    "    del dfMergeSContatenated  # delete a dataframe to save memory\n",
    "    del dfConcatenated        # delete a dataframe to save memory    \n",
    "    del dfMergeSB             # delete a dataframe to save memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a micro-bonus, I compute the percentage of bookings w.r.t. searches.\n",
    "\n",
    "The reading of the new file does not use chuncks to facilitate and accelerate the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The booking matching percentage is  3.56\n"
     ]
    }
   ],
   "source": [
    "# retrieve the column 'Booking'\n",
    "dfSearchesBooking = pd.read_csv(strNewSearchesFilename,sep='^',usecols=[listColBookingName])\n",
    "# compute the percentage\n",
    "floatBookingMatchingPercentage = sum(dfSearchesBooking[listColBookingName])/dfSearchesBooking.shape[0]*100\n",
    "print(\"The booking matching percentage is \",floatBookingMatchingPercentage.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
